from openai import OpenAI
import os
from dotenv import load_dotenv
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from fastapi.concurrency import run_in_threadpool
from connect.connect import connectDB
from PyPDF2 import PdfReader
from langchain.retrievers import ParentDocumentRetriever
from langchain.storage import InMemoryStore
from langchain_chroma import Chroma
from langchain_community.document_loaders import TextLoader
from langchain_openai import OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain.schema import Document
import json
import asyncio
from concurrent.futures import ThreadPoolExecutor
import re
from collections import Counter
from datetime import datetime
from decimal import Decimal
from typing import Dict, List, Any, Optional, Tuple

# Load environment variables
load_dotenv()

# Initialize FastAPI router
botapi = APIRouter(tags=["bot"])

# Define a request model for the incoming data
class MessageRequest(BaseModel):
    message: str


# ========================================
# Enhanced SQL Query Generation Class
# ========================================

class SQLQueryEnhancer:
    def __init__(self, client: OpenAI):
        self.client = client
        self.common_errors = {
            "no such table": "æ‰¾ä¸åˆ°æŒ‡å®šçš„è³‡æ–™è¡¨",
            "syntax error": "SQLèªæ³•éŒ¯èª¤",
            "no such column": "æ‰¾ä¸åˆ°æŒ‡å®šçš„æ¬„ä½",
            "ambiguous column": "æ¬„ä½åç¨±æ¨¡ç³Šï¼Œéœ€è¦æŒ‡å®šè¡¨æ ¼åç¨±"
        }
    
    def get_enhanced_tables_content(self) -> str:
        """Read and return enhanced database tables information with examples."""
        tables_path = "./CreateTables.txt"
        try:
            with open(tables_path, 'r', encoding='utf-8') as file:
                content = file.read()
            
            # Add common query patterns and examples
            enhanced_content = content + """
            
# ========================================
# å¸¸ç”¨æŸ¥è©¢æ¨¡å¼å’Œç¯„ä¾‹ (Common Query Patterns and Examples)
# ========================================

# 1. æ™‚é–“ç¯„åœæŸ¥è©¢ç¯„ä¾‹ï¼š
# SELECT * FROM Vehicle WHERE Doc_date BETWEEN '2024-01-01' AND '2024-12-31'
# SELECT * FROM Electricity_Usage WHERE period_start >= '2024-01-01' AND period_end <= '2024-12-31'

# 2. èšåˆæŸ¥è©¢ç¯„ä¾‹ï¼š
# SELECT SUM(liters) as total_fuel FROM Vehicle WHERE YEAR(Doc_date) = 2024
# SELECT COUNT(*) as record_count FROM users WHERE department = 1

# 3. è·¨è¡¨æŸ¥è©¢ç¯„ä¾‹ï¼š
# SELECT u.username, v.liters, v.Doc_date 
# FROM users u JOIN Vehicle v ON u.user_id = v.user_id

# 4. æ’æ”¾é‡è¨ˆç®—ç¯„ä¾‹ï¼š
# SELECT es.remark, SUM(qi.emission_equivalent) as total_emissions
# FROM Emission_Source es 
# JOIN Quantitative_Inventory qi ON es.source_id = qi.source_id
# GROUP BY es.source_id, es.remark

# 5. æœˆä»½çµ±è¨ˆç¯„ä¾‹ï¼š
# SELECT YEAR(Doc_date) as year, MONTH(Doc_date) as month, SUM(liters) as monthly_fuel
# FROM Vehicle 
# GROUP BY YEAR(Doc_date), MONTH(Doc_date)
# ORDER BY year, month

# é‡è¦æé†’ï¼š
# - ä½¿ç”¨ YEAR(), MONTH(), DAY() å‡½æ•¸è™•ç†æ—¥æœŸ
# - é‡‘é¡å’Œæ•¸é‡æ¬„ä½é€šå¸¸æ˜¯ DECIMAL é¡å‹
# - å¤–éµé—œè¯ï¼šuser_id é€£æ¥ users è¡¨ï¼Œbusiness_id é€£æ¥ Company_Info è¡¨
# - æ—¥æœŸæ ¼å¼ï¼š'YYYY-MM-DD'
# - å¸ƒæ—å€¼ï¼š0=å¦/False, 1=æ˜¯/True

# éƒ¨é–€ä»£ç¢¼å°ç…§ï¼š1=ç®¡ç†éƒ¨é–€, 2=è³‡è¨Šéƒ¨é–€, 3=æ¥­å‹™éƒ¨é–€, 4=é–€è¨ºéƒ¨é–€, 5=å¥æª¢éƒ¨é–€, 6=æª¢é©—éƒ¨é–€, 7=å…¶ä»–
# è·ä½ä»£ç¢¼å°ç…§ï¼š1=ç¸½ç¶“ç†, 2=å‰¯ç¸½ç¶“ç†, 3=ä¸»ç®¡, 4=å‰¯ä¸»ç®¡, 5=çµ„é•·, 6=å…¶ä»–
# è§’è‰²æ¬Šé™å°ç…§ï¼š0=ç³»çµ±ç®¡ç†å“¡, 1=é¡§å•, 2=ä¼æ¥­ç”¨æˆ¶
            """
            return enhanced_content
        except Exception as e:
            print(f"Error reading tables content: {e}")
            return ""

    def generate_sql_with_context(self, user_message: str) -> str:
        """Generate SQL query with enhanced context and error handling."""
        tables_content = self.get_enhanced_tables_content()
        
        # Enhanced system prompt with more specific instructions
        system_prompt = f"""
ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„SQLæŸ¥è©¢ç”Ÿæˆå°ˆå®¶ï¼Œå°ˆé–€è™•ç†ç¢³æ’æ”¾ç®¡ç†ç³»çµ±çš„è³‡æ–™åº«æŸ¥è©¢ã€‚

é‡è¦æŒ‡ç¤ºï¼š
1. **åªå›å‚³å¯åŸ·è¡Œçš„SQLæŸ¥è©¢èªå¥**ï¼Œä¸è¦åŒ…å«ä»»ä½•markdownæ ¼å¼ã€è§£é‡‹æ–‡å­—æˆ–å‰å¾Œç¶´
2. **æ ¹æ“šå•é¡Œé¸æ“‡åˆé©çš„æ¬„ä½**ï¼Œé¿å…ä¸å¿…è¦çš„ SELECT *
3. **æ­£ç¢ºä½¿ç”¨æ—¥æœŸæ ¼å¼**ï¼š'YYYY-MM-DD'ï¼Œä½¿ç”¨ YEAR(), MONTH(), DAY() å‡½æ•¸è™•ç†æ—¥æœŸæŸ¥è©¢
4. **é©ç•¶ä½¿ç”¨èšåˆå‡½æ•¸**ï¼šSUM(), COUNT(), AVG(), MAX(), MIN()
5. **æ­£ç¢ºè™•ç†JOINé—œè¯**ï¼š
   - users.user_id â†” å…¶ä»–è¡¨çš„ user_id
   - Company_Info.business_id â†” users.business_id
   - Baseline.baseline_id â†” Emission_Source.baseline_id
6. **ä½¿ç”¨è‹±æ–‡æ¨™é»ç¬¦è™Ÿ**ï¼Œé¿å…ä¸­æ–‡æ¨™é»
7. **è™•ç†æ¨¡ç³ŠæŸ¥è©¢**ï¼šä½¿ç”¨ LIKE '%keyword%'
8. **æ’åºå’Œåˆ†çµ„**ï¼šé©ç•¶ä½¿ç”¨ ORDER BY å’Œ GROUP BY

å¸¸è¦‹æŸ¥è©¢é¡å‹å°æ‡‰ï¼š
- "å¤šå°‘" â†’ COUNT() æˆ– SUM()
- "å¹³å‡" â†’ AVG()
- "æœ€å¤§/æœ€å°" â†’ MAX()/MIN()
- "è¶¨å‹¢/æ¯æœˆ/æ¯å¹´" â†’ GROUP BY YEAR(), MONTH()
- "ç¯„åœ/æœŸé–“" â†’ BETWEEN æˆ– >= AND <=
- "åŒ…å«/å«æœ‰" â†’ LIKE '%keyword%'

ä»£ç¢¼å°ç…§è¡¨ï¼š
- éƒ¨é–€ï¼š1=ç®¡ç†éƒ¨é–€, 2=è³‡è¨Šéƒ¨é–€, 3=æ¥­å‹™éƒ¨é–€, 4=é–€è¨ºéƒ¨é–€, 5=å¥æª¢éƒ¨é–€, 6=æª¢é©—éƒ¨é–€, 7=å…¶ä»–
- è·ä½ï¼š1=ç¸½ç¶“ç†, 2=å‰¯ç¸½ç¶“ç†, 3=ä¸»ç®¡, 4=å‰¯ä¸»ç®¡, 5=çµ„é•·, 6=å…¶ä»–
- è§’è‰²ï¼š0=ç³»çµ±ç®¡ç†å“¡, 1=é¡§å•, 2=ä¼æ¥­ç”¨æˆ¶

è³‡æ–™åº«çµæ§‹ï¼š
{tables_content}

è«‹æ ¹æ“šç”¨æˆ¶å•é¡Œç”Ÿæˆç²¾ç¢ºçš„SQLæŸ¥è©¢ï¼š
        """
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                temperature=0.1,  # Low temperature for consistency
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_message}
                ]
            )
            
            sql_query = response.choices[0].message.content.strip()
            
            # Clean and sanitize the SQL query
            sql_query = self.sanitize_sql_query(sql_query)
            
            return sql_query
            
        except Exception as e:
            print(f"Error generating SQL: {e}")
            raise Exception("SQLç”Ÿæˆå¤±æ•—ï¼Œè«‹é‡æ–°å˜—è©¦")

    def sanitize_sql_query(self, sql_query: str) -> str:
        """Clean and sanitize the SQL query."""
        # Remove markdown formatting
        sql_query = re.sub(r'```sql\n?|```\n?|```', '', sql_query)
        
        # Replace Chinese punctuation with English
        replacements = {
            'ï¼Œ': ',',
            'ï¼›': ';',
            'ï¼š': ':',
            '"': '"',
            '"': '"',
            ''': "'",
            ''': "'",
            'ï¼ˆ': '(',
            'ï¼‰': ')'
        }
        
        for chinese, english in replacements.items():
            sql_query = sql_query.replace(chinese, english)
        
        # Remove extra whitespace and newlines
        sql_query = ' '.join(sql_query.split())
        
        # Basic SQL injection prevention (whitelist approach)
        dangerous_keywords = ['DROP', 'DELETE', 'UPDATE', 'INSERT', 'ALTER', 'CREATE', 'EXEC', 'EXECUTE']
        sql_upper = sql_query.upper()
        
        for keyword in dangerous_keywords:
            if keyword in sql_upper:
                # Allow only specific safe UPDATE/INSERT patterns if needed
                if keyword in ['UPDATE', 'INSERT'] and 'SET' not in sql_upper:
                    continue
                else:
                    raise Exception(f"ä¸å…è¨±åŸ·è¡Œ {keyword} æ“ä½œ")
        
        return sql_query

    def execute_query_with_metadata(self, sql_query: str) -> Tuple[List[Dict], Dict]:
        """Execute query and return results with metadata."""
        conn = connectDB()
        if not conn:
            raise Exception("ç„¡æ³•é€£æ¥åˆ°è³‡æ–™åº«")
        
        try:
            cursor = conn.cursor()
            cursor.execute(sql_query)
            
            # Get column information
            column_info = []
            if cursor.description:
                column_info = [{"name": desc[0], "type": str(desc[1])} for desc in cursor.description]
            
            # Fetch results
            raw_records = cursor.fetchall()
            
            # Parse records with enhanced type handling
            parsed_records = self.parse_database_records_enhanced(raw_records, column_info)
            
            # Generate metadata
            metadata = {
                "total_records": len(raw_records),
                "columns": column_info,
                "query_type": self.analyze_query_type(sql_query),
                "execution_time": datetime.now().isoformat()
            }
            
            return parsed_records, metadata
            
        except Exception as e:
            # Enhanced error handling with suggestions
            error_msg = str(e).lower()
            suggestion = self.get_error_suggestion(error_msg)
            raise Exception(f"æŸ¥è©¢åŸ·è¡ŒéŒ¯èª¤: {suggestion}")
        finally:
            conn.close()

    def parse_database_records_enhanced(self, records: List[tuple], column_info: List[Dict]) -> List[Dict]:
        """Enhanced parsing of database records with proper type handling."""
        if not records:
            return []
        
        parsed_records = []
        for record in records:
            parsed_record = {}
            for i, value in enumerate(record):
                column_name = column_info[i]["name"] if i < len(column_info) else f"col_{i}"
                
                # Enhanced type conversion
                if value is None:
                    parsed_record[column_name] = None
                elif isinstance(value, Decimal):
                    parsed_record[column_name] = float(value)
                elif isinstance(value, datetime):
                    parsed_record[column_name] = value.strftime('%Y-%m-%d %H:%M:%S')
                elif hasattr(value, 'date') and callable(getattr(value, 'date')):
                    parsed_record[column_name] = value.strftime('%Y-%m-%d')
                elif isinstance(value, bool):
                    parsed_record[column_name] = "æ˜¯" if value else "å¦"
                elif isinstance(value, (int, float)):
                    parsed_record[column_name] = value
                else:
                    parsed_record[column_name] = str(value)
            
            parsed_records.append(parsed_record)
        
        return parsed_records

    def analyze_query_type(self, sql_query: str) -> str:
        """Analyze the type of SQL query for better response formatting."""
        sql_upper = sql_query.upper()
        
        if "COUNT(" in sql_upper:
            return "è¨ˆæ•¸æŸ¥è©¢"
        elif "SUM(" in sql_upper:
            return "ç¸½å’ŒæŸ¥è©¢"
        elif "AVG(" in sql_upper:
            return "å¹³å‡å€¼æŸ¥è©¢"
        elif "GROUP BY" in sql_upper:
            return "åˆ†çµ„çµ±è¨ˆæŸ¥è©¢"
        elif "JOIN" in sql_upper:
            return "é—œè¯æŸ¥è©¢"
        elif "ORDER BY" in sql_upper:
            return "æ’åºæŸ¥è©¢"
        else:
            return "ä¸€èˆ¬æŸ¥è©¢"

    def get_error_suggestion(self, error_msg: str) -> str:
        """Provide helpful suggestions based on error messages."""
        for error_pattern, suggestion in self.common_errors.items():
            if error_pattern in error_msg:
                return suggestion
        
        if "conversion failed" in error_msg:
            return "æ•¸æ“šé¡å‹è½‰æ›å¤±æ•—ï¼Œè«‹æª¢æŸ¥æ—¥æœŸæ ¼å¼æˆ–æ•¸å€¼æ ¼å¼"
        elif "timeout" in error_msg:
            return "æŸ¥è©¢è¶…æ™‚ï¼Œè«‹å˜—è©¦ç¸®å°æŸ¥è©¢ç¯„åœ"
        else:
            return "æŸ¥è©¢åŸ·è¡Œå¤±æ•—ï¼Œè«‹æª¢æŸ¥SQLèªæ³•æˆ–è¯çµ¡ç³»çµ±ç®¡ç†å“¡"

    def generate_user_friendly_response(self, user_message: str, parsed_records: List[Dict], 
                                      metadata: Dict) -> str:
        """Generate a user-friendly response based on query results."""
        
        # Enhanced response generation prompt
        response_prompt = f"""
æ ¹æ“šç”¨æˆ¶å•é¡Œå’ŒæŸ¥è©¢çµæœï¼Œç”Ÿæˆä¸€å€‹æ¸…æ™°ã€æœ‰æ„ç¾©çš„å›ç­”ã€‚

ç”¨æˆ¶å•é¡Œï¼š{user_message}
æŸ¥è©¢é¡å‹ï¼š{metadata.get('query_type', 'ä¸€èˆ¬æŸ¥è©¢')}
çµæœç­†æ•¸ï¼š{metadata.get('total_records', 0)}
æ¬„ä½è³‡è¨Šï¼š{[col['name'] for col in metadata.get('columns', [])]}

æŸ¥è©¢çµæœï¼š
{json.dumps(parsed_records, ensure_ascii=False, indent=2) if parsed_records else 'ç„¡è³‡æ–™'}

è«‹æŒ‰ç…§ä»¥ä¸‹è¦æ±‚ç”Ÿæˆå›ç­”ï¼š

1. **ç›´æ¥å›ç­”ç”¨æˆ¶å•é¡Œ**ï¼Œé¿å…é¡¯ç¤ºåŸå§‹è³‡æ–™åº«æ ¼å¼
2. **æ•¸æ“šæ‘˜è¦**ï¼šå¦‚æœæœ‰å¤šç­†è³‡æ–™ï¼Œæä¾›é‡é»æ‘˜è¦
3. **æ•¸å€¼æ ¼å¼åŒ–**ï¼š
   - é‡‘é¡ï¼šæ·»åŠ åƒåˆ†ä½é€—è™Ÿ
   - æ—¥æœŸï¼šä½¿ç”¨æ˜“è®€æ ¼å¼
   - å¸ƒæ—å€¼ï¼šä½¿ç”¨"æ˜¯/å¦"
4. **çµæ§‹åŒ–å‘ˆç¾**ï¼š
   - çµ±è¨ˆçµæœï¼šä½¿ç”¨æ¸…æ¥šçš„æ•¸å­—è¡¨é”
   - åˆ—è¡¨è³‡æ–™ï¼šä½¿ç”¨æ¢åˆ—æˆ–è¡¨æ ¼æ ¼å¼
   - è¶¨å‹¢è³‡æ–™ï¼šæè¿°è®ŠåŒ–è¶¨å‹¢
5. **ä¸Šä¸‹æ–‡è§£é‡‹**ï¼šé©ç•¶è§£é‡‹çµæœçš„æ„ç¾©
6. **ç„¡è³‡æ–™è™•ç†**ï¼šå¦‚æœæ²’æœ‰æ‰¾åˆ°è³‡æ–™ï¼Œèªªæ˜åŸå› ä¸¦å»ºè­°æ›¿ä»£æ–¹æ¡ˆ
7. **ä»£ç¢¼è½‰æ›**ï¼šå°‡æ•¸å­—ä»£ç¢¼è½‰æ›ç‚ºæœ‰æ„ç¾©çš„æè¿°
   - éƒ¨é–€ä»£ç¢¼ï¼š1=ç®¡ç†éƒ¨é–€, 2=è³‡è¨Šéƒ¨é–€, 3=æ¥­å‹™éƒ¨é–€, 4=é–€è¨ºéƒ¨é–€, 5=å¥æª¢éƒ¨é–€, 6=æª¢é©—éƒ¨é–€, 7=å…¶ä»–
   - è·ä½ä»£ç¢¼ï¼š1=ç¸½ç¶“ç†, 2=å‰¯ç¸½ç¶“ç†, 3=ä¸»ç®¡, 4=å‰¯ä¸»ç®¡, 5=çµ„é•·, 6=å…¶ä»–
   - è§’è‰²ä»£ç¢¼ï¼š0=ç³»çµ±ç®¡ç†å“¡, 1=é¡§å•, 2=ä¼æ¥­ç”¨æˆ¶

ç‰¹åˆ¥æ³¨æ„ï¼š
- é¿å…é¡¯ç¤ºæŠ€è¡“æ€§æ¬„ä½åç¨±ï¼ˆå¦‚col_0, col_1ï¼‰
- æä¾›å¯¦ç”¨çš„æ´å¯Ÿå’Œå»ºè­°
        """
        
        try:
            result = self.client.chat.completions.create(
                model="gpt-4o",
                temperature=0.2,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯å°ˆæ¥­çš„æ•¸æ“šåˆ†æåŠ©æ‰‹ï¼Œæ“…é•·å°‡è³‡æ–™åº«æŸ¥è©¢çµæœè½‰æ›ç‚ºæ¸…æ™°æ˜“æ‡‚çš„å•†æ¥­æ´å¯Ÿã€‚è«‹æä¾›å¯¦ç”¨ã€æº–ç¢ºä¸”æ˜“æ–¼ç†è§£çš„å›ç­”ã€‚"},
                    {"role": "user", "content": response_prompt}
                ]
            )
            
            return result.choices[0].message.content
            
        except Exception as e:
            print(f"Error generating response: {e}")
            # Fallback to basic response
            return self.generate_fallback_response(parsed_records, metadata)

    def generate_fallback_response(self, parsed_records: List[Dict], metadata: Dict) -> str:
        """Generate a basic fallback response when AI response generation fails."""
        if not parsed_records:
            return "æŸ¥è©¢å®Œæˆï¼Œä½†æ²’æœ‰æ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„è³‡æ–™ã€‚"
        
        total_records = metadata.get('total_records', len(parsed_records))
        
        if total_records == 1:
            return f"æ‰¾åˆ° 1 ç­†è³‡æ–™ï¼š{parsed_records[0]}"
        elif total_records <= 5:
            response = f"æ‰¾åˆ° {total_records} ç­†è³‡æ–™ï¼š\n"
            for i, record in enumerate(parsed_records, 1):
                response += f"{i}. {record}\n"
            return response
        else:
            response = f"æ‰¾åˆ° {total_records} ç­†è³‡æ–™ï¼Œé¡¯ç¤ºå‰ 3 ç­†ï¼š\n"
            for i, record in enumerate(parsed_records[:3], 1):
                response += f"{i}. {record}\n"
            response += f"... é‚„æœ‰ {total_records - 3} ç­†è³‡æ–™"
            return response


# ========================================
# Main Bot Functions
# ========================================

@botapi.post("/botapi")
async def botmessage(request: MessageRequest):
    # Set the OpenAI API key
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    if not client:
        raise HTTPException(status_code=500, detail="OpenAI API key is not set in the environment.")
    
    # Get user message
    user_message = request.message

    # Determine intent
    intent_response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": f"""
You are an intelligent assistant that replies to the user's questions with precision. 
Your primary focus is to understand the user's intent before responding. 

You have the following tools:
- query: Use this when the user asks for information that requires external sources or research, you have these table: {get_tables_content()}
- answer: Use this when the user asks about Carbon Footprint Verification, including its process, standards, calculations, or related details.
- others: Use this for any other questions or requests unrelated to Carbon Footprint Verification or external queries.

Your task is to:
1. **Accurately determine the user's intent** and respond with one of the following intents ONLY:
    - query
    - answer
    - others
            """},
            {"role": "user", "content": user_message},
        ]
    )
    
    # Extract intent from the response
    intent = intent_response.choices[0].message.content.strip().lower()
    print(f"Intent: {intent}")

    # Process based on intent
    if intent == "query":
        return await handle_query_intent(client, user_message)
    elif intent == "answer":
        return await handle_answer_intent(client, user_message)
    else:
        # Handle other intents
        print("Intent is others.")
        return {"response": "æŠ±æ­‰ï¼Œç¢³æ™ºéƒåƒ…èƒ½å›ç­”è³‡æ–™åº«ä¸­å’Œç¢³ç›¤æŸ¥ç›¸é—œçš„å•é¡Œ"}


def get_tables_content():
    """Read and return database tables information."""
    enhancer = SQLQueryEnhancer(None)  # We only need the file reading functionality
    return enhancer.get_enhanced_tables_content()


# Enhanced Query Handler (replaces the original one)
async def handle_query_intent(client, user_message):
    """Enhanced handler for database query intent."""
    enhancer = SQLQueryEnhancer(client)
    
    try:
        # Generate SQL query
        sql_query = enhancer.generate_sql_with_context(user_message)
        print(f"Generated SQL: {sql_query}")
        
        # Execute query with metadata
        parsed_records, metadata = enhancer.execute_query_with_metadata(sql_query)
        
        # Generate user-friendly response
        response = enhancer.generate_user_friendly_response(user_message, parsed_records, metadata)
        
        return {"response": response}
        
    except Exception as e:
        error_msg = str(e)
        print(f"Error in enhanced query handling: {error_msg}")
        
        # Provide specific error responses
        if "ä¸å…è¨±åŸ·è¡Œ" in error_msg:
            return {"response": "æŠ±æ­‰ï¼Œç‚ºäº†å®‰å…¨è€ƒé‡ï¼Œä¸å…è¨±åŸ·è¡Œæ­¤é¡æ“ä½œã€‚"}
        elif "ç„¡æ³•é€£æ¥" in error_msg:
            return {"response": "æŠ±æ­‰ï¼Œç›®å‰ç„¡æ³•é€£æ¥åˆ°è³‡æ–™åº«ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"}
        elif "SQLç”Ÿæˆå¤±æ•—" in error_msg:
            return {"response": "æŠ±æ­‰ï¼Œç„¡æ³•ç†è§£æ‚¨çš„å•é¡Œï¼Œè«‹å˜—è©¦é‡æ–°è¡¨è¿°ã€‚"}
        else:
            return {"response": f"è™•ç†æŸ¥è©¢æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{error_msg}ã€‚è«‹å˜—è©¦é‡æ–°è¡¨è¿°æ‚¨çš„å•é¡Œã€‚"}


# ========================================
# Legacy Functions (kept for compatibility)
# ========================================

def parse_database_records(records, column_names=None):
    """
    Parse database records into a more readable format.
    (Legacy function - kept for compatibility)
    """
    if not records:
        return []
    
    parsed_records = []
    for record in records:
        parsed_record = {}
        for i, value in enumerate(record):
            # Convert different data types to readable format
            if isinstance(value, Decimal):
                parsed_record[f'col_{i}'] = float(value)
            elif isinstance(value, datetime):
                parsed_record[f'col_{i}'] = value.strftime('%Y-%m-%d %H:%M:%S')
            elif hasattr(value, 'date') and callable(getattr(value, 'date')):  # datetime.date
                parsed_record[f'col_{i}'] = value.strftime('%Y-%m-%d')
            else:
                parsed_record[f'col_{i}'] = str(value) if value is not None else None
        
        parsed_records.append(parsed_record)
    
    return parsed_records


def get_column_info(cursor, table_name):
    """
    Get column information for a table to better understand the data structure.
    (Legacy function - kept for compatibility)
    """
    try:
        # Try to get column information (this syntax might vary depending on your database)
        cursor.execute(f"PRAGMA table_info({table_name})")
        columns = cursor.fetchall()
        return [col[1] for col in columns]  # Column names are usually in index 1
    except:
        # If PRAGMA doesn't work, try alternative method
        try:
            cursor.execute(f"SELECT * FROM {table_name} LIMIT 0")
            return [description[0] for description in cursor.description]
        except:
            return None


# ========================================
# RAG-based Answer Functions (unchanged)
# ========================================

async def handle_answer_intent(client, user_message):
    """Handle RAG-based answer intent using PDF documents."""
    # Initialize and prepare vector store
    vectorstore = prepare_vectorstore()
    
    # Detect user language
    language = detect_user_language(client, user_message)
    print(f"Detected language: {language}")
    
    # 1. Retrieve top-k chunks
    top_chunks = retrieve_top_k_chunks(vectorstore, user_message, k=7)
    print(f"Step1: Retrieved top 7 chunks, number of chunks: {len(top_chunks)}")

    # 2. Pointwise scoring, select best chunks
    final_chunks = await select_best_chunks_async(client, user_message, top_chunks, top_n=3)
    print(f"Step2: Selected top 3 chunks based on pointwise scoring")

    # 3. Summarize selected chunks with detected language
    final_answer = summarize_chunks(client, user_message, final_chunks, language=language)

    return {"response": final_answer}


def detect_user_language(client, user_message):
    """Detect the user's language from their message."""
    # Use a language detection prompt with the OpenAI API
    language_detection = client.chat.completions.create(
        model="gpt-4o",
        temperature=0,
        messages=[
            {"role": "system", "content": """
            Detect the language of the user's message and respond with only the language code.
            Use standard language codes like:
            - 'en' for English
            - 'zh-tw' for Traditional Chinese
            - 'ja' for Japanese
            - etc.
            
            Only return the language code, no other text.
            """},
            {"role": "user", "content": user_message}
        ]
    )
    
    language_code = language_detection.choices[0].message.content.strip().lower()
    
    # Validate language code (basic validation)
    if not language_code or len(language_code) > 10:
        # Default to English if detection fails
        return "en"
    
    return language_code

def prepare_vectorstore():
    """Prepare and return the vector store for RAG."""
    persist_directory = "./RAGè³‡è¨Š/vectorstore_db"
    populated_flag = os.path.join(persist_directory, ".populated")

    # Ensure the directory for ChromaDB exists
    os.makedirs(persist_directory, exist_ok=True)

    # Initialize Vector Store
    vectorstore = Chroma(
        collection_name="full_documents", 
        embedding_function=OpenAIEmbeddings(),
        persist_directory=persist_directory
    )

    # If vector database not populated, add PDF content
    if not os.path.exists(populated_flag):
        folder_path = './RAGè³‡è¨Š'
        all_pdfname = []

        # Prepare all PDF filenames
        for filename in os.listdir(folder_path):
            if filename.endswith(".pdf"):
                pdf_path = os.path.join(folder_path, filename)
                all_pdfname.append(pdf_path)

        # Add PDFs to vector database
        for pdf_name in all_pdfname:
            file_path = os.path.join(pdf_name)
            pdf_text = extract_text_from_pdf(file_path)

            if not pdf_text.strip():
                print(f"âš ï¸ PDF '{pdf_name}' æ²’æœ‰æå–åˆ°ä»»ä½•æ–‡å­—ã€‚è·³éæ­¤æª”æ¡ˆã€‚")
                continue

            child_splitter = RecursiveCharacterTextSplitter(chunk_size=2000)
            text_chunks = child_splitter.split_text(pdf_text)

            if not text_chunks:
                print(f"âš ï¸ PDF '{pdf_name}' çš„æ–‡å­—åˆ‡å‰²çµæœç‚ºç©ºã€‚è·³éæ­¤æª”æ¡ˆã€‚")
                continue

            documents = [Document(page_content=chunk) for chunk in text_chunks if chunk.strip()]

            if not documents:
                print(f"âš ï¸ PDF '{pdf_name}' çš„ documents åˆ—è¡¨ç‚ºç©ºã€‚è·³éæ­¤æª”æ¡ˆã€‚")
                continue

            # Add to vector database
            vectorstore.add_documents(documents)

        with open(populated_flag, "w") as f:
            f.write("populated")
        print("âœ… æ‰€æœ‰ PDF çš„å…§å®¹å·²åŠ å…¥å‘é‡è³‡æ–™åº«ã€‚")
    else:
        print("ğŸ”„ å‘é‡è³‡æ–™åº«å·²æœ‰è³‡æ–™")

    return vectorstore


def extract_text_from_pdf(file_path):
    """Extract text from a PDF file."""
    reader = PdfReader(file_path)
    text = ""
    for page in reader.pages:
        page_text = page.extract_text()
        if page_text:
            text += page_text
    return text


def retrieve_top_k_chunks(vectorstore, user_query, k=5):
    """Retrieve the top-k most relevant chunks from the vector store."""
    sub_docs = vectorstore.similarity_search(user_query, k=k)
    return [doc.page_content for doc in sub_docs]


def score_chunk_sync(client, query, chunk, index):
    """Score a single chunk for relevance to the query."""
    score_prompt = f"""
è©•ä¼°ä»»å‹™ï¼šå°å…§å®¹ç‰‡æ®µèˆ‡ä½¿ç”¨è€…å•é¡Œçš„ç›¸é—œæ€§é€²è¡Œé‡åŒ–è©•åˆ†

ä½¿ç”¨è€…å•é¡Œ: {query}

å¾…è©•ä¼°å…§å®¹ç‰‡æ®µ:
{chunk}

è©•åˆ†æ¨™æº–ï¼ˆç¸½åˆ†10åˆ†ï¼‰:
1. ç›´æ¥å›ç­”å•é¡Œ (0-3åˆ†)
   - 3åˆ†ï¼šå®Œå…¨ä¸”ç›´æ¥å›ç­”å•é¡Œæ ¸å¿ƒ
   - 2åˆ†ï¼šéƒ¨åˆ†å›ç­”å•é¡Œ
   - 1åˆ†ï¼šåƒ…æåŠå•é¡Œä½†æœªç›´æ¥å›ç­”
   - 0åˆ†ï¼šå®Œå…¨æœªå›ç­”å•é¡Œ

2. ç›¸é—œèƒŒæ™¯çŸ¥è­˜ (0-2åˆ†)
   - 2åˆ†ï¼šæä¾›è±å¯Œä¸”å¿…è¦çš„èƒŒæ™¯è³‡è¨Š
   - 1åˆ†ï¼šæä¾›ä¸€äº›ç›¸é—œèƒŒæ™¯
   - 0åˆ†ï¼šæœªæä¾›ç›¸é—œèƒŒæ™¯

3. å°ˆæ¥­æ€§å’Œæº–ç¢ºæ€§ (0-3åˆ†)
   - 3åˆ†ï¼šå…§å®¹å°ˆæ¥­ã€æº–ç¢ºä¸”æœ‰æ·±åº¦
   - 2åˆ†ï¼šå…§å®¹å¤§è‡´æº–ç¢ºä½†ç¼ºä¹æ·±åº¦
   - 1åˆ†ï¼šå…§å®¹æœ‰è¼•å¾®éŒ¯èª¤æˆ–éæ–¼ç°¡åŒ–
   - 0åˆ†ï¼šå…§å®¹æœ‰æ˜é¡¯éŒ¯èª¤æˆ–èª¤å°

4. å®Œæ•´æ€§ (0-2åˆ†)
   - 2åˆ†ï¼šå…§å®¹å®Œæ•´ï¼Œç„¡éœ€é¡å¤–è³‡è¨Š
   - 1åˆ†ï¼šå…§å®¹åŸºæœ¬å®Œæ•´ä½†æœ‰éºæ¼
   - 0åˆ†ï¼šå…§å®¹ç‰‡æ®µä¸”ä¸å®Œæ•´

æ€è€ƒæ­¥é©Ÿï¼š
1. ä»”ç´°é–±è®€ä½¿ç”¨è€…å•é¡Œï¼Œç¢ºå®šæ ¸å¿ƒéœ€æ±‚
2. é€æ¢è©•ä¼°å…§å®¹ç‰‡æ®µåœ¨å„æ¨™æº–ä¸‹çš„è¡¨ç¾
3. ç‚ºæ¯å€‹æ¨™æº–åˆ†é…é©ç•¶åˆ†æ•¸
4. è¨ˆç®—ç¸½åˆ†

åªè¼¸å‡ºæœ€çµ‚ç¸½åˆ†ï¼ˆ0-10çš„æ•´æ•¸ï¼‰ã€‚ä¸è¦åŒ…å«ä»»ä½•æ–‡å­—ã€è§£é‡‹æˆ–åˆ†æéç¨‹ã€‚
"""

    score_response = client.chat.completions.create(
        model="gpt-4o",
        temperature=0,
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ç²¾ç¢ºçš„å…§å®¹è©•åˆ†å°ˆå®¶ã€‚ä½ å¿…é ˆéµå¾ªæŒ‡ç¤ºï¼Œåªå›å‚³ä¸€å€‹0-10ä¹‹é–“çš„æ•´æ•¸ä½œç‚ºè©•åˆ†çµæœï¼Œä¸èƒ½æœ‰ä»»ä½•å…¶ä»–æ–‡å­—ã€æ¨™é»æˆ–èªªæ˜ã€‚é•åæ­¤è¦å‰‡å°‡å°è‡´è©•åˆ†ç³»çµ±å¤±æ•ˆã€‚"},
            {"role": "user", "content": score_prompt}
        ]
    )

    content = score_response.choices[0].message.content.strip()
    print(f"Chunk {index} raw score: {content}")

    try:
        # Try to convert response to integer
        score = int(content)
        # Ensure score is in 0-10 range
        return max(0, min(score, 10)), chunk
    except Exception as e:
        print(f"Error parsing score for chunk {index}: {e}")
        # If parsing fails, try to extract number from text
        number_match = re.search(r'\d+', content)
        if number_match:
            try:
                score = int(number_match.group())
                return max(0, min(score, 10)), chunk
            except:
                pass
        return 5, chunk  # Default to middle value


async def select_best_chunks_async(client, query, chunks, top_n=3):
    """Asynchronously score chunks and select the best ones."""
    print(f"Scoring {len(chunks)} chunks asynchronously...")
    
    # Use ThreadPoolExecutor for potentially blocking API calls
    scored_chunks = []
    with ThreadPoolExecutor(max_workers=min(10, len(chunks))) as executor:
        # Create task list
        futures = []
        for i, chunk in enumerate(chunks):
            future = executor.submit(score_chunk_sync, client, query, chunk, i)
            futures.append(future)
        
        # Wait for all tasks to complete
        for i, future in enumerate(futures):
            try:
                score, chunk = future.result()
                scored_chunks.append((score, chunk))
                print(f"Completed {i+1}/{len(chunks)} evaluations")
            except Exception as e:
                print(f"Error in chunk evaluation {i}: {e}")
                # If scoring fails, give low score but keep the chunk
                scored_chunks.append((1, chunks[i]))
    
    # Sort by score and take top_n
    scored_chunks.sort(key=lambda x: x[0], reverse=True)  # Sort from high to low
    top_chunks = [chunk for _, chunk in scored_chunks[:top_n]]
    
    return top_chunks


def summarize_chunks(client, query, chunks, language=None):
    """
    Summarize relevant chunks to generate a final answer.
    
    Args:
        client: OpenAI client
        query (str): The user's question
        chunks (list): List of relevant text segments
        language (str, optional): Preferred language code (e.g., 'en', 'zh-tw') according to user's language
            
    Returns:
        str: Summarized response in markdown format based on the chunks
    """
    # Handle empty chunks case
    if not chunks:
        return "No relevant information found to answer your query."
    
    # Prepare language instruction
    lang_instruction = ""
    if language:
        lang_instruction = f"Please respond in {language}. "
    
    # Create system prompt
    system_prompt = (
        f"{lang_instruction}Based on the user's question: '{query}', "
        "synthesize the following relevant information into a comprehensive answer. "
        "Maintain factual accuracy and cite information directly from the provided content."
    )
    
    try:
        # Combine chunks with proper separation and context
        formatted_chunks = "\n\n--- CHUNK START ---\n" + "\n--- CHUNK END ---\n\n--- CHUNK START ---\n".join(chunks) + "\n--- CHUNK END ---"
        
        # Make API call with error handling
        summarize_response = client.chat.completions.create(
            model="gpt-4o",
            temperature=0.2,  # Slight randomness for more natural responses while maintaining consistency
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": formatted_chunks}
            ],
            max_tokens=1024  # Set reasonable output length limit
        )
        
        return summarize_response.choices[0].message.content
    
    except Exception as e:
        # Log error and return fallback response
        print(f"Error in summarization: {str(e)}")
        return "Sorry, I encountered an issue while processing your request. Please try again."