import requests
from urllib.parse import urlencode
from bs4 import BeautifulSoup
from dotenv import load_dotenv
from openai import OpenAI
from PyPDF2 import PdfReader
import os
import re
import ast
from connect.connect import connectDB
from datetime import datetime
import time

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# å¾ç’°å¢ƒè®Šæ•¸å–å¾— API Key
serp_api_key = os.getenv("SERPAPI_API_KEY")
if not serp_api_key:
    raise ValueError("âŒ SERPAPI_API_KEY æœªè¨­å®šï¼")

openai_api_key = os.getenv("OPENAI_API_KEY")
if not openai_api_key:
    raise ValueError("âŒ OPENAI_API_KEY æœªè¨­å®šï¼")

client = OpenAI(api_key=openai_api_key)

# å„²å­˜å¤šæ¬¡æŸ¥è©¢çµæœ
search_results = []
extracted_coefficients = []
verified_coefficients = None

# å®šç¾©æŸ¥è©¢å‡½æ•¸
def search_emission_factors(query, year=None, num_results=3):
    """åŸ·è¡Œæœå°‹ä¸¦è¿”å›çµæœ"""
    search_query = query
    if year:
        search_query += f" {year}å¹´"
    
    params = {
        "engine": "google",
        "q": search_query,
        "location": "Taiwan",
        "hl": "zh-TW",
        "gl": "tw",
        "google_domain": "google.com",
        "num": num_results,
        "start": 0,
        "safe": "active",
        "api_key": serp_api_key
    }
    
    base_url = "https://serpapi.com/search.json"
    query_string = urlencode(params)
    full_url = f"{base_url}?{query_string}"
    
    try:
        response = requests.get(full_url, timeout=15)
        response.raise_for_status()
        data = response.json()
        return data.get("organic_results", [])
    except requests.exceptions.RequestException as e:
        print(f"âŒ API è«‹æ±‚å¤±æ•—ï¼š{e}")
        return []

# PDF è™•ç†å‡½æ•¸
def process_pdf(pdf_url):
    print(f"ğŸ“¥ ä¸‹è¼‰ PDFï¼š{pdf_url}")
    pdf_response = requests.get(pdf_url)
    if pdf_response.status_code == 200:
        pdf_filename = "downloaded_file.pdf"
        with open(pdf_filename, "wb") as file:
            file.write(pdf_response.content)
        print("âœ… PDF ä¸‹è¼‰å®Œæˆï¼Œé–‹å§‹è§£æå…§å®¹...")

        # è®€å– PDF ä¸¦æå–æ–‡å­—
        pdf_text = ""
        try:
            reader = PdfReader(pdf_filename)
            for page in reader.pages:
                page_text = page.extract_text() or ""
                pdf_text += page_text
        except Exception as e:
            print(f"âŒ ç„¡æ³•è§£æ PDFï¼š{e}")
            return None
        
        # ç§»é™¤ PDF æ–‡ä»¶
        os.remove(pdf_filename)
        return pdf_text
    else:
        print(f"âŒ ç„¡æ³•ä¸‹è¼‰ PDFï¼ŒHTTPç‹€æ…‹ç¢¼ï¼š{pdf_response.status_code}")
        return None

# å¾ç¶²é æ“·å–å…§å®¹
def extract_web_content(url):
    try:
        page_response = requests.get(url, headers={"User-Agent": "Mozilla/5.0"}, timeout=15)
        page_response.raise_for_status()
        # è‡ªå‹•æª¢æ¸¬ä¸¦è¨­ç½®ç·¨ç¢¼
        page_response.encoding = page_response.apparent_encoding or 'utf-8'
        # è§£æç¶²é å…§å®¹
        soup = BeautifulSoup(page_response.content, "html.parser")
        article_text = soup.get_text(separator="\n").strip()
        # æª¢æŸ¥ä¸¦æ›¿æ›ç„¡æ³•è§£ç¢¼çš„å­—å…ƒ
        if not article_text or "ï¿½" in article_text:
            article_text = page_response.content.decode('utf-8', errors='replace').strip()
        return article_text
    except requests.exceptions.RequestException as e:
        print(f"âŒ æ“·å–ç¶²é å…§å®¹æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        return None

# ä½¿ç”¨ AI æ“·å–æ’æ”¾ä¿‚æ•¸
def extract_coefficients(text, source_url="", year=""):
    if not text:
        return None
    
    ai_prompt = (
        "è«‹æ ¹æ“šä»¥ä¸‹æ–‡æœ¬æä¾›ç’°å¢ƒéƒ¨å…¬å‘Šçš„æº«å®¤æ°£é«”æ’æ”¾ä¿‚æ•¸ã€‚"
        "è«‹å¾ä»¥ä¸‹æ–‡æœ¬ä¸­æ“·å–å„ç¨®ç‡ƒæ–™çš„ CO2ã€CH4ã€N2O ç‡ƒæ–™å–®ä½ç†±å€¼ä¹‹æ’æ”¾ä¿‚æ•¸ï¼Œä¸¦æŒ‰ç…§ä»¥ä¸‹æ ¼å¼æ•´ç†æˆäºŒç¶­é™£åˆ—ï¼Œå–®ä½ï¼šï¼ˆå…¬æ–¤/å…†ç„¦è€³ï¼‰(kg/TJ)"
        "["
        "['è»Šç”¨æ±½æ²¹', 'CO2', 'CH4', 'N2O'],"
        "['æŸ´æ²¹', 'CO2', 'CH4', 'N2O'],"
        "['ä¹™çƒ·', 'CO2', 'CH4', 'N2O'],"
        "['å¤©ç„¶æ°£', 'CO2', 'CH4', 'N2O'],"
        "['äº‹æ¥­å»¢æ£„ç‰©', 'CO2', 'CH4', 'N2O'],"
        "['è»Šç”¨æ±½æ²¹-æœªæ§åˆ¶', 'CO2', 'CH4', 'N2O'],"
        "['è»Šç”¨æ±½æ²¹-æ°§åŒ–è§¸åª’', 'CO2', 'CH4', 'N2O'],"
        "['è»Šç”¨æ±½æ²¹-1995å¹´å¾Œä¹‹ä½é‡Œç¨‹è¼•å‹è»Šè¼›', 'CO2', 'CH4', 'N2O'],"
        "['æŸ´æ²¹(ç§»å‹•ç‡ƒç‡’æ’æ”¾æº)', 'CO2', 'CH4', 'N2O']"
        "]\n"
        "æ–‡æœ¬å…§å®¹é¡¯ç¤ºï¼šè»Šç”¨æ±½æ²¹ \nGasoli ne Motor Gasoli ne 69,300 3 0.6 ï¼Œä»£è¡¨è»Šç”¨æ±½æ²¹çš„ CO2 æ’æ”¾ä¿‚æ•¸ç‚º 69,300 å…¬æ–¤/å…†ç„¦è€³ï¼ŒCH4 æ’æ”¾ä¿‚æ•¸ç‚º 3 å…¬æ–¤/å…†ç„¦è€³ï¼ŒN2O æ’æ”¾ä¿‚æ•¸ç‚º 0.6 å…¬æ–¤/å…†ç„¦è€³ã€‚"
        "è«‹åœ¨é™£åˆ—ä¸­é¡¯ç¤º[è»Šç”¨æ±½æ²¹, 69300, 3, 0.6]ã€‚è«‹æ³¨æ„æ•¸å­—ä¸è¦åŠ ä¸Šåƒåˆ†ä½é€—è™Ÿã€‚"
        "æŸ´æ²¹ Gas/Diesel Oil 74,100 3 0.6ï¼Œä»£è¡¨æŸ´æ²¹çš„ CO2 æ’æ”¾ä¿‚æ•¸ç‚º 74,100 å…¬æ–¤/å…†ç„¦è€³ï¼ŒCH4 æ’æ”¾ä¿‚æ•¸ç‚º 3 å…¬æ–¤/å…†ç„¦è€³ï¼ŒN2O æ’æ”¾ä¿‚æ•¸ç‚º 0.6 å…¬æ–¤/å…†ç„¦è€³ã€‚"
        "è«‹åœ¨é™£åˆ—ä¸­é¡¯ç¤º[æŸ´æ²¹, 74100, 3, 0.6]ã€‚è«‹æ³¨æ„æ•¸å­—ä¸è¦åŠ ä¸Šåƒåˆ†ä½é€—è™Ÿã€‚"
        "è€Œè»Šç”¨æ±½æ²¹-æœªæ§åˆ¶ ã€è»Šç”¨æ±½æ²¹-æ°§åŒ–è§¸åª’ã€è»Šç”¨æ±½æ²¹-1995å¹´å’ŒæŸ´æ²¹(ç§»å‹•ç‡ƒç‡’æ’æ”¾æº)çš„CO2æ’æ”¾ä¿‚æ•¸ç­‰æ–¼è»Šç”¨æ±½æ²¹å’ŒæŸ´æ²¹çš„CO2å›ºå®šç‡ƒç‡’æ’æ”¾ä¿‚æ•¸"
        f"é€™å€‹æ–‡ä»¶ä¾†æºç¶²å€æ˜¯: {source_url}ï¼Œç™¼å¸ƒå¹´ä»½æ‡‰è©²æ˜¯: {year if year else 'ä¸ç¢ºå®š'}"
        "è«‹å‹™å¿…å¾æ–‡ä»¶ä¸­ç¢ºèªç™¼å¸ƒå¹´ä»½ï¼Œä¸¦åœ¨å›æ‡‰ä¸­æ¨™æ˜ã€‚å¦‚æœæ‰¾ä¸åˆ°æ’æ”¾ä¿‚æ•¸ï¼Œå¡«å…¥nullã€‚"
        "æ³¨æ„ï¼šåªéœ€è¦è¼¸å‡ºä»¥ä¸‹æ ¼å¼çš„JSONï¼Œä¸éœ€è¦å…¶ä»–ä»»ä½•æ ¼å¼ã€è§£é‡‹ã€markdownï¼š\n"
        "{"
        "  \"year\": \"æ–‡ä»¶ç™¼å¸ƒå¹´ä»½\","
        "  \"source\": \"æ–‡ä»¶ä¾†æºç¶²å€\","
        "  \"coefficients\": ["
        "    [\"ç‡ƒæ–™é¡å‹\", CO2æ•¸å€¼, CH4æ•¸å€¼, N2Oæ•¸å€¼],"
        "    ..."
        "  ]"
        "}"
        "ä»¥ä¸‹æ˜¯æ“·å–åˆ°çš„æ–‡æœ¬å…§å®¹ï¼š\n"
        f"{text[:10000]}"  # é™åˆ¶æ–‡æœ¬é•·åº¦é¿å…è¶…å‡º token é™åˆ¶
    )

    try:
        completion = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "You are a helpful assistant specialized in extracting greenhouse gas emission factors from official documents."},
                {"role": "user", "content": ai_prompt}
            ],
            response_format={"type": "json_object"}
        )
        result = completion.choices[0].message.content
        return result
    except Exception as e:
        print(f"âŒ AI è™•ç†å¤±æ•—ï¼š{e}")
        return None

# æ¯”è¼ƒå’Œé©—è­‰ä¸åŒä¾†æºçš„ä¿‚æ•¸
def verify_coefficients(coefficients_list):
    if not coefficients_list or len(coefficients_list) < 1:
        return None
    
    # å¦‚æœåªæœ‰ä¸€å€‹çµæœï¼Œç›´æ¥è¿”å›
    if len(coefficients_list) == 1:
        return coefficients_list[0]
    
    verification_prompt = (
    "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„æº«å®¤æ°£é«”æ•¸æ“šåˆ†æå°ˆå®¶ï¼Œè«‹ç³»çµ±æ€§è©•ä¼°ä»¥ä¸‹æº«å®¤æ°£é«”æ’æ”¾ä¿‚æ•¸ä¾†æºï¼Œç¢ºå®šæœ€å¯é çš„æ•¸æ“šã€‚\n\n"
    "è©•ä¼°æ­¥é©Ÿï¼š\n"
    "1. åˆ†ææ¯å€‹ä¿‚æ•¸ä¾†æºçš„ç™¼å¸ƒå¹´ä»½\n"
    "2. è©•ä¼°ä¾†æºæ©Ÿæ§‹çš„æ¬Šå¨æ€§ï¼ˆå¦‚æ”¿åºœæ©Ÿæ§‹ã€åœ‹éš›çµ„ç¹”å„ªæ–¼ç§äººçµ„ç¹”ï¼‰\n"
    "3. æª¢æŸ¥æ•¸æ“šçš„å®Œæ•´æ€§å’Œè©³ç´°ç¨‹åº¦\n"
    "4. æ¯”è¼ƒæ•¸æ“šèˆ‡å…¬èªæ¨™æº–çš„ä¸€è‡´æ€§\n"
    "5. è«‹ä»¥é©ç”¨æ–¼å°ç£çš„æ¨™æº–è©•ä¼°\n\n"
    
    "éœ€è©•ä¼°çš„ä¿‚æ•¸æ•¸æ“šï¼š\n"
    f"{coefficients_list}\n\n"
    
    "è«‹åœ¨è©•ä¼°å¾Œæä¾›ä»¥ä¸‹ç¢ºåˆ‡JSONæ ¼å¼çš„å›æ‡‰ï¼Œä¸è¦æœ‰ä»»ä½•å¤šé¤˜æ–‡å­—ï¼š\n"
    "{\n"
    "  \"most_reliable\": {å®Œæ•´çš„æœ€å¯é ä¿‚æ•¸JSONå°è±¡},\n"
    "  \"reason\": \"é¸æ“‡æ­¤ä¿‚æ•¸çš„3-5å€‹å…·é«”ç†ç”±\",\n"
    "  \"year\": \"ç¢ºèªçš„ç™¼å¸ƒå¹´ä»½\",\n"
    "  \"confidence_level\": \"é«˜/ä¸­/ä½\",\n"
    "  \"additional_notes\": \"ä»»ä½•éœ€è¦ä½¿ç”¨è€…æ³¨æ„çš„é‡è¦èªªæ˜\"\n"
    "}\n\n"
    
    "è«‹ç¢ºä¿ä½ çš„å›æ‡‰æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ï¼Œå¯ä»¥ç›´æ¥è¢«ç¨‹å¼è§£æã€‚å¦‚æœæ•¸æ“šä¸­æœ‰æ˜é¡¯çŸ›ç›¾æˆ–ç„¡æ³•ç¢ºå®šæœ€å¯é ä¾†æºï¼Œè«‹åœ¨additional_notesä¸­èªªæ˜ã€‚"
)

    
    try:
        completion = client.chat.completions.create(
    model="gpt-4o",
    temperature=0,  # é™ä½æº«åº¦ä»¥æé«˜ä¸€è‡´æ€§
    messages=[
        {"role": "system", "content": "ä½ æ˜¯å°ç£å°ˆæ¥­çš„æº«å®¤æ°£é«”æ•¸æ“šèˆ‡ç¢³æ’æ”¾åˆ†æå°ˆå®¶ã€‚è«‹åŸºæ–¼ç§‘å­¸è­‰æ“šå’Œæœ€ä½³å¯¦è¸åˆ†ææ•¸æ“šï¼Œä¸¦åš´æ ¼æŒ‰ç…§è¦æ±‚çš„JSONæ ¼å¼å›æ‡‰ã€‚"},
        {"role": "user", "content": verification_prompt}
    ],
    response_format={"type": "json_object"}  # å¼·åˆ¶JSONæ ¼å¼å›æ‡‰
)

        result = completion.choices[0].message.content
        return result
    except Exception as e:
        print(f"âŒ é©—è­‰è™•ç†å¤±æ•—ï¼š{e}")
        return None

# ä¸»è¦åŸ·è¡Œéç¨‹
def main():
    search_years = [None, "2025", "2024", "2023"]  # Noneä»£è¡¨ä¸æŒ‡å®šå¹´ä»½ï¼Œæœå°‹æœ€æ–°è³‡æ–™
    
    for year in search_years:
        print(f"\nğŸ” æœå°‹ {year if year else 'æœ€æ–°'} å¹´åº¦æ’æ”¾ä¿‚æ•¸...\n")
        results = search_emission_factors("ç’°å¢ƒéƒ¨å…¬å‘Š å…¬å‘Šæº«å®¤æ°£é«”æ’æ”¾ä¿‚æ•¸.pdf", year)
        
        if not results:
            print(f"âš ï¸ æœªæ‰¾åˆ° {year if year else 'æœ€æ–°'} å¹´åº¦çµæœï¼Œå˜—è©¦ä¸‹ä¸€å€‹å¹´ä»½ã€‚")
            continue
            
        for i, result in enumerate(results, 1):
            title = result.get("title", "ç„¡æ¨™é¡Œ")
            snippet = result.get("snippet", "ç„¡æè¿°")
            link = result.get("link", "#")
            
            print(f"{i}. ğŸ“° **{title}**\n")
            print(f"ğŸ“– æ‘˜è¦ï¼š{snippet}\nğŸ”— é€£çµï¼š{link}\n")
            
            # å„²å­˜æœå°‹çµæœ
            search_results.append({
                "title": title,
                "link": link,
                "year": year,
                "snippet": snippet
            })
            
            # æª¢æŸ¥æ˜¯å¦ç‚º PDF æª”æ¡ˆ
            if re.search(r'\.pdf$', link, re.IGNORECASE):
                article_text = process_pdf(link)
            else:
                article_text = extract_web_content(link)
                
            if article_text:
                # ä½¿ç”¨ AI æ“·å–ä¿‚æ•¸
                extracted_json = extract_coefficients(article_text, link, year)
                if extracted_json:
                    try:
                        extracted_data = ast.literal_eval(extracted_json)
                        extracted_coefficients.append(extracted_data)
                        print(f"âœ… æˆåŠŸå¾ä¾†æº {i} æå–æ’æ”¾ä¿‚æ•¸ï¼")
                    except (SyntaxError, ValueError) as e:
                        print(f"âŒ è§£ææå–çš„ JSON å¤±æ•—ï¼š{e}")
                else:
                    print("âš ï¸ ç„¡æ³•å¾è©²ä¾†æºæå–æ’æ”¾ä¿‚æ•¸ã€‚")
            else:
                print("âš ï¸ ç„¡æ³•æå–æ–‡æœ¬å…§å®¹ã€‚")
                
        # å¦‚æœå·²æå–è¶³å¤ çš„ä¿‚æ•¸ï¼Œé€²å…¥é©—è­‰éšæ®µ
        if len(extracted_coefficients) >= 2:
            break
    
    # é©—è­‰æ’æ”¾ä¿‚æ•¸
    if extracted_coefficients:
        print("\nğŸ” é©—è­‰æ’æ”¾ä¿‚æ•¸ä¸­...\n")
        verified_result = verify_coefficients(extracted_coefficients)
        
        if verified_result:
            try:
                verified_data = ast.literal_eval(verified_result)
                verified_coefficients = verified_data.get("most_reliable", {}).get("coefficients", [])
                verified_year = verified_data.get("year", "æœªçŸ¥")
                verification_reason = verified_data.get("reason", "")
                
                print(f"âœ… é©—è­‰å®Œæˆï¼ä½¿ç”¨ {verified_year} å¹´åº¦æ•¸æ“šã€‚")
                print(f"ğŸ“ é©—è­‰ç†ç”±ï¼š{verification_reason}")
            except (SyntaxError, ValueError) as e:
                print(f"âŒ è§£æé©—è­‰çµæœå¤±æ•—ï¼š{e}")
                verified_coefficients = extracted_coefficients[0].get("coefficients", [])
    else:
        print("âš ï¸ æœªèƒ½æå–ä»»ä½•æ’æ”¾ä¿‚æ•¸è³‡æ–™ï¼Œç„¡æ³•é€²è¡Œé©—è­‰ã€‚")
        return
    
    # è¨ˆç®—æœ€çµ‚çµæœ
    if verified_coefficients:
        # è½‰æ›è¨ˆç®—
        Kcal_to_TJ = 4.1868 * 10**-9  # æ ¹æ“šå°ç£æº«å®¤æ°£é«”æ’æ”¾é‡ç›¤æŸ¥ä½œæ¥­æŒ‡å¼•113å¹´ç‰ˆ 
        TJ_to_Kcal = 1 / Kcal_to_TJ  
        
        # å»ºç«‹è¨ˆç®—ç”¨é™£åˆ—
        calculation_array = []
        for item in verified_coefficients:
            if len(item) >= 4:  # ç¢ºä¿æœ‰è¶³å¤ çš„å…ƒç´ 
                fuel_type = item[0]
                
                # ç¢ºä¿æ‰€æœ‰æ•¸å€¼éƒ½æ˜¯æ•¸å­—
                try:
                    co2 = float(item[1]) if item[1] is not None else 0
                    ch4 = float(item[2]) if item[2] is not None else 0
                    n2o = float(item[3]) if item[3] is not None else 0
                    calculation_array.append([fuel_type, co2, ch4, n2o])
                except (ValueError, TypeError):
                    print(f"âš ï¸ ç„¡æ³•è½‰æ› {fuel_type} çš„æ’æ”¾ä¿‚æ•¸ç‚ºæ•¸å­—ã€‚")
                    calculation_array.append([fuel_type, 0, 0, 0])
        
        # LHV values corresponding to each fuel type
        fuel_lhv_map = {
            "è»Šç”¨æ±½æ²¹": 7800,
            "æŸ´æ²¹": 8400,
            "ä¹™çƒ·": 15.40,
            "å¤©ç„¶æ°£": 8000,
            "äº‹æ¥­å»¢æ£„ç‰©": 1,
            "è»Šç”¨æ±½æ²¹-æœªæ§åˆ¶": 7800,
            "è»Šç”¨æ±½æ²¹-æ°§åŒ–è§¸åª’": 7800,
            "è»Šç”¨æ±½æ²¹-1995å¹´å¾Œä¹‹ä½é‡Œç¨‹è¼•å‹è»Šè¼›": 7800,
            "æŸ´æ²¹(ç§»å‹•ç‡ƒç‡’æ’æ”¾æº)": 8400
        }
        
        # Convert and calculate final values
        final_results = []
        for row in calculation_array:
            fuel_type = row[0]
            
            # è½‰æ›ç‚º kg/Kcal
            co2_per_kcal = row[1] / TJ_to_Kcal
            ch4_per_kcal = row[2] / TJ_to_Kcal
            n2o_per_kcal = row[3] / TJ_to_Kcal
            
            # å–å¾—å°æ‡‰çš„ LHV å€¼
            lhv = fuel_lhv_map.get(fuel_type, 0)
            
            # è¨ˆç®—æ’æ”¾é‡
            co2_emission = co2_per_kcal * lhv
            ch4_emission = ch4_per_kcal * lhv
            n2o_emission = n2o_per_kcal * lhv
            
            final_results.append([
                fuel_type, 
                co2_per_kcal,
                ch4_per_kcal,
                n2o_per_kcal,
                lhv,
                co2_emission,
                ch4_emission,
                n2o_emission
            ])
        
        # é¡¯ç¤ºçµæœ
        print("\næœ€çµ‚è¨ˆç®—çµæœ:")
        print("ç‡ƒæ–™é¡å‹ | CO2(kg/Kcal) | CH4(kg/Kcal) | N2O(kg/Kcal) | LHV | CO2æ’æ”¾é‡ | CH4æ’æ”¾é‡ | N2Oæ’æ”¾é‡")
        for row in final_results:
            formatted_row = [row[0]] + ["{:.2E}".format(x) if isinstance(x, float) else x for x in row[1:]]
            print(" | ".join(str(x) for x in formatted_row))
        
        # å­˜å…¥è³‡æ–™åº«
        save_to_database(final_results)
    else:
        print("âš ï¸ æ²’æœ‰å¯ç”¨çš„é©—è­‰ä¿‚æ•¸ï¼Œç„¡æ³•è¨ˆç®—æœ€çµ‚çµæœã€‚")

def save_to_database(results):
    conn = connectDB()
    if not conn:
        print("âŒ ç„¡æ³•é€£æ¥è³‡æ–™åº«")
        return
    
    cursor = conn.cursor()
    
    try:
        if not results:
            print("âš ï¸ ç„¡æ•¸æ“šå¯å­˜å…¥è³‡æ–™åº«")
            return

        # å…ˆæ¸…é™¤èˆŠæ•¸æ“š
        cursor.execute("DELETE FROM Fuel_Factors")

        # æ‰¹é‡æ’å…¥æ•¸æ“š
        query = """
        INSERT INTO Fuel_Factors (FuelType, CO2_Emission, CH4_Emission, N2O_Emission, 
                                 LowerHeatingValue, CO2_Total, CH4_Total, N2O_Total, 
                                 update_time)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
        """
        values = [
            (
                row[0],  # FuelType
                row[1],  # CO2_Emission
                row[2],  # CH4_Emission
                row[3],  # N2O_Emission
                row[4],  # LowerHeatingValue
                row[5],  # CO2_Total
                row[6],  # CH4_Total
                row[7],  # N2O_Total
                datetime.now().strftime('%Y-%m-%d %H:%M:%S')  # æ ¼å¼åŒ– update_time
            )
            for row in results
        ]
        
        cursor.executemany(query, values)  # ä½¿ç”¨æ‰¹é‡æ’å…¥
        conn.commit()
        print("âœ… è³‡æ–™æˆåŠŸå­˜å…¥è³‡æ–™åº«ï¼")

    except Exception as e:
        conn.rollback()  # è‹¥ç™¼ç”ŸéŒ¯èª¤ï¼Œå›æ»¾
        print(f"âŒ è³‡æ–™åº«éŒ¯èª¤ï¼š{e}")

    finally:
        conn.close()  # ç¢ºä¿é—œé–‰é€£æ¥

if __name__ == "__main__":
    main()